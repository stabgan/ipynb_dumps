{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3ccf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@author: GITAA\n",
    "\"\"\"\n",
    "'''\n",
    "=============================================================================\n",
    "    Control structures\n",
    "        - If elif family\n",
    "        - For \n",
    "        - While \n",
    "    Functions\n",
    "\n",
    "=============================================================================\n",
    "'''\n",
    "# =============================================================================\n",
    "# Importing necessary libraries\n",
    "# =============================================================================\n",
    "import os               # ‘os’ library to change the working directory\n",
    "import pandas as pd     # ‘pandas’ library to work with dataframes\n",
    "import numpy as np      # ‘numpy’ library to perform numeric operations\n",
    "\n",
    "# =============================================================================\n",
    "# Importing data \n",
    "# =============================================================================\n",
    "cars_data = pd.read_csv('Toyota.csv', index_col=0, na_values=[\"??\",\"????\"])\n",
    "\n",
    "# Creating copy of original data\n",
    "cars_data1 = cars_data.copy()\n",
    "\n",
    "\"\"\"\n",
    "    Control Structures in Python\n",
    "    - Execute certain commands only when certain condition(s) is (are) satisfied-\n",
    "      (if-then-else)\n",
    "    - Execute certain commands repeatedly and use a certain logic to stop\n",
    "      the iteration - (for, while loops)\n",
    "\n",
    "\"\"\"\n",
    "\"\"\"\n",
    " - Creating 3 bins from the ‘Price’ variable using If Else and For Loops\n",
    " - The binned values will be stored as classes in a new column, ‘Price Class’\n",
    "\"\"\"\n",
    "# Inserting at end- index can only be positive\n",
    "\n",
    "cars_data1.insert(10,\"Price_Class\",\"\")\n",
    "\n",
    "# =============================================================================\n",
    "# if else and for loops\n",
    "# =============================================================================\n",
    "\n",
    "\"\"\"\n",
    "    if else and for loops are implemented and the observations are separated into three categories:   \n",
    "    Price \n",
    "       - up to 8450\n",
    "       - between 8450 and 11950 \n",
    "       - greater than 11950\n",
    "    The classes have been stored in a new column ‘Price Class’\n",
    "\"\"\"\n",
    "import time\n",
    "start = time.time()\n",
    "for i in range(0,len(cars_data1['Price']),1):\n",
    "    if (cars_data1['Price'][i]<=8450):\n",
    "        cars_data1['Price_Class'][i]=\"Low\"\n",
    "    elif ((cars_data1['Price'][i]>11950)):\n",
    "        cars_data1['Price_Class'][i]=\"High\"\n",
    "    else: cars_data1['Price_Class'][i]=\"Medium\"\n",
    "\n",
    "cars_data1['Price_Class'].value_counts()\n",
    "\n",
    "end=time.time()\n",
    "end-start\n",
    "\n",
    "# =============================================================================\n",
    "# while loop\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "    - A while loop is used whenever you want to execute statements until a\n",
    "      specific condition is violated\n",
    "    - Here a while loop is used over the length of the column ‘Price_Class’ \n",
    "      and an if else loop is used to bin the values and store it as classes\n",
    "\"\"\"\n",
    "i=0\n",
    "start = time.time()\n",
    "while i<len(cars_data1['Price']):\n",
    "    if (cars_data1['Price'][i]<=8450):\n",
    "        cars_data1['Price_Class'][i]=\"Low\"\n",
    "    elif ((cars_data1['Price'][i]>11950)):\n",
    "        cars_data1['Price_Class'][i]=\"High\"\n",
    "    else: cars_data1['Price_Class'][i]=\"Medium\"\n",
    "    i=i+1\n",
    "    \n",
    "end = time.time()\n",
    "end-start\n",
    "\n",
    "\"\"\"\n",
    "    Series.value_counts() returns series containing count of unique values\n",
    "\"\"\"\n",
    "\n",
    "cars_data1['Price_Class'].value_counts()\n",
    "cars_data1.insert(11,\"Km_per_month\",0)\n",
    "\n",
    "# =============================================================================\n",
    "# FUNCTIONS \n",
    "# =============================================================================\n",
    "\n",
    "\"\"\"\n",
    "    - A function accepts input arguments and produces an output by executing\n",
    "      valid commands present in the function\n",
    "    - Function name and file names need not be the same\n",
    "    - A file can have one or more function definitions\n",
    "    - Functions are created using\n",
    "      def function_name(parameters):\n",
    "       statements\n",
    "    - Since statements are not demarcated explicitly, \n",
    "      it is essential to follow correct indentation practises\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "    - Converting the Age variable from months to years by defining a function\n",
    "    - The converted values will be stored in a new column, ‘Age_Converted’\n",
    "    - Hence, inserting a new column \n",
    "\"\"\"\n",
    "cars_data1.insert(12,\"Age_Converted\",0)\n",
    "# Here, a function c_convert has been defined\n",
    "# The function takes arguments and returns one value\n",
    "\n",
    "def c_convert(val):\n",
    "    val_converted=val/12\n",
    "    return val_converted\n",
    "\n",
    "cars_data1[\"Age_Converted\"] = c_convert(cars_data1['Age'])\n",
    "cars_data1[\"Age_Converted\"] = round(cars_data1[\"Age_Converted\"],1)\n",
    "\n",
    "# =============================================================================\n",
    "# Function with multiple inputs and outputs\n",
    "# =============================================================================\n",
    "\n",
    "# Functions returning multiple output\n",
    "# Converting months to years and getting kilometers run per month\n",
    "\n",
    "def c_convert(val1,val2):\n",
    "    val_converted=val1/12\n",
    "    ratio=val2/val1\n",
    "    return [val_converted,ratio]\n",
    "\n",
    "cars_data1[\"Age_Converted\"],cars_data1[\"Km_per_month\"] = \\\n",
    "c_convert(cars_data1['Age'],cars_data1['KM'])\n",
    "\n",
    "# =============================================================================\n",
    "# END OF SCRIPT\n",
    "# =============================================================================\n",
    "\n",
    "#%%\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@author: GITAA\n",
    "\"\"\"\n",
    "'''\n",
    "    Basic plots using matplotlib library:\n",
    "    - Scatter plot\n",
    "    - Histogram\n",
    "    - Bar plot\n",
    "    Basic plots using seaborn library:\n",
    "    - Scatter plot\n",
    "    - Histogram\n",
    "    - Bar plot\n",
    "    - Box and whiskers plot\n",
    "    - Pairwise plots\n",
    "'''\n",
    "# =============================================================================\n",
    "# Importing necessary libraries\n",
    "# =============================================================================\n",
    "import os               # ‘os’ library to change the working directory\n",
    "import pandas as pd     # ‘pandas’ library to work with dataframes\n",
    "import numpy as np      # ‘numpy’ library to perform numeric operations\n",
    "import matplotlib.pyplot as plt # to visualize the data\n",
    "import seaborn as sns   # to visualize the data\n",
    "# =============================================================================\n",
    "# Importing data (replacing special chars with nan values)\n",
    "# =============================================================================\n",
    "\n",
    "cars_data = pd.read_csv('Toyota.csv', index_col=0, na_values=[\"??\",\"????\"])\n",
    "\n",
    "# Removing missing values from the dataframe\n",
    "cars_data.dropna(axis = 0, inplace=True)\n",
    "\n",
    "# =============================================================================\n",
    "# SCATTER PLOT - MATPLOTLIB\n",
    "# =============================================================================\n",
    "\n",
    "plt.scatter(cars_data['Age'], cars_data['Price'], c  ='red', )\n",
    "plt.title('Scatter PLot')\n",
    "plt.xlabel('Age (months)')\n",
    "plt.ylabel('Price (Euros)')\n",
    "plt.show()\n",
    "\n",
    "#The price of the car decreases as age of the car increases\n",
    "\n",
    "# =============================================================================\n",
    "#  HISTOGRAM - MATPLOTLIB\n",
    "# =============================================================================\n",
    "# Histogram with default arguments\n",
    "plt.hist(cars_data['KM'])\n",
    "\n",
    "plt.hist(cars_data['KM'], color = 'red', edgecolor = 'white', bins =5)\n",
    "\"\"\"\n",
    "Frequency distribution of kilometre of the cars shows that most of the cars have\n",
    "travelled between 50000 – 100000 km and there are only few cars with more distance travelled\n",
    "\"\"\"\n",
    "# for any bin value, the minor tick lables remains the same\n",
    "# only the no.of bars changes\n",
    "\n",
    "# histogram for the given range of values\n",
    "plt.hist(cars_data['KM'], color='blue', edgecolor='white', bins=10, range=(5000,15000))\n",
    "plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# BAR PLOT - MATPLOTLIB\n",
    "# =============================================================================\n",
    "\n",
    "counts   = [979, 120, 12]\n",
    "fuelType = ('Petrol', 'Diesel', 'CNG')  # Set the labels of the xticks\n",
    "index    = np.arange(len(fuelType))     # Set the location of the xticks\n",
    "\n",
    "plt.bar(index, counts, color=['red', 'blue', 'cyan'], edgecolor='darkblue')\n",
    "plt.title('Frequency plot of FuelType')\n",
    "plt.xlabel('Fuel Type')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(index, fuelType,rotation = 90)\n",
    "plt.show()\n",
    "\n",
    "\"\"\"\n",
    "Bar plot of fuel type shows that most of the cars have petrol as fuel type\n",
    "\"\"\"\n",
    "# =============================================================================\n",
    "# SACTTER PLOT - SEABORN\n",
    "# =============================================================================\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "#1. Scatter plot of Price vs Age with default arguments\n",
    "sns.regplot(x=cars_data['Price'], y=cars_data['Age'])\n",
    "\n",
    "# By default, fit_reg = True\n",
    "# It estimates and plots a regression model relating the x and y variables\n",
    "\n",
    "# 2. Scatter plot of Price vs Age without the regression fit line\n",
    "sns.regplot(x=cars_data['Price'], y=cars_data['Age'], fit_reg=False)\n",
    "\n",
    "# 3. Scatter plot of Price vs Age by customizing the appearance of markers\n",
    "sns.regplot(x=cars_data['Price'], y=cars_data['Age'], marker=\"*\", fit_reg=False)\n",
    "sns.plt.show()\n",
    "#%%\n",
    "sns.regplot(x=cars_data['Price'], y=cars_data['Age'],\n",
    "            marker=\"o\", fit_reg=False,\n",
    "            scatter_kws={\"color\":\"green\",\"alpha\":0.3,\"s\":200} )\n",
    "sns.plt.show()\n",
    "#%%\n",
    "# 4. Scatter plot of Price vs Age by FuelType\n",
    "# Using hue parameter, including another variable to show the fuel types\n",
    "# categories with different colors\n",
    "\n",
    "sns.lmplot(x = 'Age', y = 'Price', data = cars_data, fit_reg = False,\n",
    "           hue = 'FuelType', legend = True, palette=\"Set1\")\n",
    "sns.plt.show()\n",
    "#%%\n",
    "# 4. Differentiating categories using markers\n",
    "sns.lmplot(x = 'Age', y = 'Price', data = cars_data, fit_reg = False,\n",
    "           hue = 'FuelType', legend = True, markers=[\"o\", \"x\", \"1\"])\n",
    "sns.plt.show()\n",
    "#%%\n",
    "\n",
    "# =============================================================================\n",
    "# HISTOGRAM - SEABORN\n",
    "# =============================================================================\n",
    "# 1.Histogram of Age with default kernel density estimate \n",
    "sns.distplot(cars_data['Age'] )\n",
    "#%%\n",
    "# 2. Histogram without kernel density estimate\n",
    "sns.distplot(cars_data['Age'], hist=True, kde=False)\n",
    "#%%\n",
    "# 3. Histogram with fixed no. of bins\n",
    "sns.distplot(cars_data['Age'], bins=5 )\n",
    "#%%\n",
    "\n",
    "# =============================================================================\n",
    "# BAR PLOT - SEABORN\n",
    "# =============================================================================\n",
    "\n",
    "# Frequency distribution of fuel type of the cars\n",
    "sns.countplot(x=\"FuelType\", data=cars_data)\n",
    "\n",
    "# Grouped bar plot of FuelType and Automatic\n",
    "sns.countplot(x=\"FuelType\", data=cars_data, hue = \"Automatic\")\n",
    "\n",
    "sns.countplot(y=\"FuelType\", data=cars_data, hue = \"Automatic\")\n",
    "\n",
    "sns.countplot(x=\"FuelType\", data=cars_data, palette=\"Set2\")\n",
    "\n",
    "# =============================================================================\n",
    "# Box and whiskers plot\n",
    "# =============================================================================\n",
    "# 1. Box plot for a numerical varaible\n",
    "#    Box and whiskers plot of Price to visually interpret the five-number summary\n",
    "\n",
    "sns.boxplot(y=cars_data[\"Price\"] )\n",
    "\n",
    "#2. Box and whiskers plot for numerical vs categorical variable\n",
    "#   Price of the cars for various fuel types\n",
    "\n",
    "sns.boxplot(x = cars_data['FuelType'], y = cars_data[\"Price\"])\n",
    "\n",
    "#3. Box plot for multiple numerical varaibles\n",
    "sns.boxplot(data = cars_data.ix[:,0:4])\n",
    "\n",
    "#4. Grouped box and whiskers plot of Price vs FuelType and Automatic\n",
    "\n",
    "sns.boxplot(x=\"FuelType\",  y = cars_data[\"Price\"],\n",
    "            hue=\"Automatic\", data=cars_data, palette=\"Set2\")\n",
    "\n",
    "# =============================================================================\n",
    "# Box-whiskers plot and Histogram\n",
    "# =============================================================================\n",
    "\n",
    "# Let’s plot box-whiskers plot and histogram on the same window\n",
    "# Split the plotting window into 2 parts\n",
    "\n",
    "f, (ax_box, ax_hist) = plt.subplots(2, sharex=True, gridspec_kw={\"height_ratios\": (.15, .85)})\n",
    "\n",
    "# Now, create two plots\n",
    "sns.boxplot(cars_data[\"Price\"], ax=ax_box)\n",
    "sns.distplot(cars_data[\"Price\"], ax=ax_hist, kde = False)\n",
    "\n",
    "# Remove x axis name for the boxplot\n",
    "ax_box.set(xlabel='')\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# END OF SCRIPT\n",
    "# =============================================================================\n",
    "\n",
    "#%%\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@author: GITAA\n",
    "\"\"\"\n",
    "# =============================================================================\n",
    "# DATA PREPARATION\n",
    "# =============================================================================\n",
    "\n",
    "#%%\n",
    "# To work with dataframes\n",
    "import pandas as pd\n",
    "\n",
    "# To perform numerical operations\n",
    "import numpy as np\n",
    "\n",
    "#%%\n",
    "# Importing data\n",
    "\n",
    "demoDetails    =  pd.read_csv(\"demoDetails.csv\"   , index_col=0)\n",
    "acDetails      =  pd.read_csv(\"acDetails.txt\"     , sep=\"\\t\")\n",
    "serviceDetails =  pd.read_csv(\"serviceDetails.csv\", index_col=0)\n",
    "\n",
    "# By setting 'index_col = 0', 1st column will be the index column\n",
    "\n",
    "#%%\n",
    "# Data Wrangling\n",
    "\"\"\"\n",
    " - We are interested in merging acDetails, demoDetails and serviceDetails \n",
    " - Before merging we need to make necessary checks !\n",
    " - What are the mandatory checks you should look for before merging ?\n",
    " -   1. Are there any duplicate records?\n",
    "     2. Whether the customer ID is common across all the files ?\n",
    "\"\"\"\n",
    "\n",
    "# 1. Are there any duplicate records?\n",
    "\n",
    "len(np.unique(demoDetails['customerID']))\n",
    "\n",
    "len(np.unique(acDetails['customerID']))\n",
    "\n",
    "len(np.unique(serviceDetails['customerID']))\n",
    "\n",
    "# Yes, there is one duplicate record across all the three dataframes\n",
    "\n",
    "#%%\n",
    "# ======================== Determining duplicate records =================================\n",
    "\n",
    "# To determine the duplicate records 'duplicated()' can be used\n",
    "\n",
    "demoDetails.duplicated(subset=['customerID'], keep=False)\n",
    "\n",
    "# duplicated function returns a Boolean Series with True value\n",
    "# for each duplicated row\n",
    "\n",
    "# So now let's subset the rows and look at the duplications\n",
    "\n",
    "demoDetails[demoDetails.duplicated(['customerID'],keep=False)]\n",
    "\n",
    "acDetails[acDetails.duplicated(['customerID'],keep=False)]\n",
    "\n",
    "serviceDetails[serviceDetails.duplicated(['customerID'],keep=False)]\n",
    "\n",
    "#%%\n",
    "# ====================== Removing duplicate records ================================\n",
    "\n",
    "demoDetails    =  demoDetails.drop_duplicates()\n",
    "\n",
    "acDetails      =  acDetails.drop_duplicates()\n",
    "\n",
    "serviceDetails =  serviceDetails.drop_duplicates()\n",
    "\n",
    "# First occurrence of the duplicate row is kept and\n",
    "# subsequent occurrence have been removed\n",
    "\n",
    "#%%\n",
    "\n",
    "# 2. Whether the customer ID is common across all the files ?\n",
    "\n",
    "# syntax: dataframe1.equals(dataframe2)\n",
    "\n",
    "acDetails.customerID.equals(demoDetails.customerID)\n",
    "\n",
    "serviceDetails.customerID.equals (demoDetails.customerID)\n",
    "\n",
    "acDetails.customerID.equals (serviceDetails.customerID)\n",
    "\n",
    "# Looks like they are indeed identical!\n",
    "\n",
    "#%%\n",
    "# ====================== Joining three dataframes =============================\n",
    "\n",
    "# Syntax: pd.merge(df1, df2, on=['Column_Name'], how='inner')\n",
    "\n",
    "churn  =  pd.merge(demoDetails, acDetails, on = \"customerID\")\n",
    "\n",
    "churn  =  pd.merge(churn,serviceDetails,   on = \"customerID\")\n",
    "\n",
    "churn1 =  churn.copy()\n",
    "\n",
    "#%%\n",
    "# ============ Data Exploration / Understanding the data ======================\n",
    "\n",
    "churn1.info()\n",
    "\n",
    "\"\"\" Points to note:\n",
    "-'tenure' has been read as object instead of integer\n",
    "-'SeniorCitizen' has been read as float64 instead of object\n",
    "- Missing values present in few variables\n",
    "\"\"\"\n",
    "# unique() finds the unique elements of an array\n",
    "np.unique(churn1['tenure'], return_counts = True )\n",
    "\n",
    "# 'tenure' has been read as object instead of integer\n",
    "# because of values One/Four which are strings\n",
    "\n",
    "np.unique(churn1['SeniorCitizen'])\n",
    "\n",
    "# 'SeniorCitizen' has been read as float64 instead of int64 since it has values nan values\n",
    "\n",
    "# Checking frequencies of each categories in a variable\n",
    "\n",
    "categotical_data = churn1.select_dtypes(include=['object']).copy()\n",
    "\n",
    "categotical_data.columns\n",
    "\n",
    "categotical_data['gender'].value_counts()\n",
    "\n",
    "# categotical_data.value_counts() AttributeError:\n",
    "\n",
    "categotical_data = categotical_data.drop(['customerID','tenure'],axis = 1)\n",
    "\n",
    "frequencies      = categotical_data.apply(lambda x: x.value_counts()).T.stack()\n",
    "\n",
    "print(frequencies)\n",
    "\n",
    "\"\"\" Points to note:\n",
    "- 'Dependents' should have only 2 levels (Yes/No) but it has 3 due \n",
    "-  the special character '1@#' that has been read as another level\n",
    "\"\"\"\n",
    "# Summary of numerical variables\n",
    "\n",
    "summary = churn1.describe()\n",
    "\n",
    "print(summary)\n",
    "\n",
    "#%%\n",
    "# ======================================== Data Cleaning ======================\n",
    "\n",
    "# Cleaning column 'tenure'\n",
    "\n",
    "# Replacing 'Four' by 4 and 'One' by 1 in 'tenure'\n",
    "\n",
    "churn1['tenure'] = churn1.tenure.replace(\"Four\", 4)\n",
    "\n",
    "churn1['tenure'] = churn1.tenure.replace(\"One\", 1)\n",
    "\n",
    "churn1['tenure'] = churn1.tenure.astype(int)\n",
    "\n",
    "print(churn1['tenure'])\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "# Cleaning column 'Dependents'\n",
    "\"\"\" 'Dependents' should have only 2 levels (Yes/No) but it has 3 due \n",
    "     the special character '1@#' that has been read as another level\"\"\"\n",
    "\n",
    "# Gives counts- class 'No' has the max count\n",
    "\n",
    "pd.crosstab(index=churn1['Dependents'], columns=\"count\")\n",
    "\n",
    "# Replacing \"1@#\" with 'No'\n",
    "\n",
    "churn1['Dependents'] = churn1['Dependents'].replace(\"1@#\", 'No')\n",
    "\n",
    "# Verifying if the special characters were converted to desired class\n",
    "\n",
    "table_dependents  = pd.crosstab(index = churn1['Dependents'], columns=\"count\")\n",
    "\n",
    "print(table_dependents)\n",
    "\n",
    "#%%\n",
    "\"\"\"\n",
    "    - Checking for logical fallacies in the data\n",
    "    - Approaches to resolve the logical fallacies in the data\n",
    "    - Outlier detection using boxplot\n",
    "    - Approaches to fill in missing values    \n",
    "\"\"\"\n",
    "############################### Logical Checks ################################\n",
    "# 1. Checking if the 'customerID' is consistent\n",
    "\n",
    "print(churn1['customerID'])\n",
    "\n",
    "\"\"\"\n",
    "I  Interms of total number of characters\n",
    "II Sequence of charaters i.e. first 4 characters of customerID should be \n",
    "    numbers followed by hyphen and 5 upper case letters\n",
    "    \n",
    "\"\"\"\n",
    "# I\n",
    "# to get the index of customerID whose length != 10\n",
    "len_ind = [i for i,value in enumerate(churn1.customerID) if len(value)!=10]\n",
    "\n",
    "import re\n",
    "pattern = '^[0-9]{4,4}-[A-Z]{5,5}'\n",
    "\n",
    "p = re.compile(pattern)\n",
    "type(p)\n",
    "\n",
    "q = [i for i,value in enumerate(churn1.customerID) if p.match(str(value))==None]\n",
    "print(q)\n",
    "\n",
    "fp1 = re.compile('^[A-Z]{5,5}-[0-9]{4,4}')\n",
    "fp2 = re.compile('^[0-9]{4,4}/[A-Z]{5,5}')\n",
    "\n",
    "for i in q:\n",
    "    false_str = str(churn1.customerID[i])\n",
    "    if(fp1.match(false_str)):\n",
    "        str_splits=false_str.split('-')\n",
    "        churn1.customerID[i]=str_splits[1]+'-'+str_splits[0]\n",
    "    elif(fp2.match(false_str)):\n",
    "        churn1.customerID[i]=false_str.replace('/','-')\n",
    "\n",
    "#%%\n",
    "#################################################################################\n",
    "# Logical checks - check for fallacies in the data\n",
    "# If Internet service = No, then all the allied services related to internet\n",
    "# should be no.\n",
    "\n",
    "# Is that the case?\n",
    "\n",
    "# Subsetting Internet Service and allied services\n",
    "y = churn1[(churn1.InternetService =='No')]\n",
    "z = y.iloc[:,13:20]\n",
    "\n",
    "\"\"\"\n",
    "   Some observations have InterService= No and Yes in certain allied services\n",
    "   This is a logical fallacy!\n",
    "   Two ways of approach:\n",
    "   => Brute force method- wherever InternetService = No, blindly make other \n",
    "      related fields 'No'\n",
    "   => Logical approach- If there are say 2 or more Yes in the allied services,\n",
    "      then go back and change InternetService= Yes \n",
    "                       else change the allied services = No\n",
    "\"\"\"\n",
    "# Logical approach\n",
    "\n",
    "for i,row in z.iterrows():\n",
    "    yes_cnt=row.str.count('Yes').sum()\n",
    "    if(yes_cnt>=2):\n",
    "        z.loc[i].InternetService='Yes'\n",
    "    else:\n",
    "        z.loc[i,:]='No internet service'\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# OUTLIER DETECTION\n",
    "###############################################################################\n",
    "\n",
    "## looking for any outliers\n",
    "churn1.tenure.describe()\n",
    "\n",
    "# Outlier detection using boxplot\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.boxplot(y = churn1['tenure'])\n",
    "\n",
    "# Replacing outliers by median of column 'tenure'\n",
    "churn1['tenure'] = np.where(churn1['tenure']>=500,\n",
    "                            churn1['tenure'].median(), churn1['tenure'])\n",
    "\n",
    "# Checking the summary of the column 'tenure’ after median imputation\n",
    "churn1['tenure'].describe()\n",
    "sns.boxplot(y = churn1['tenure'])\n",
    "\n",
    "# =============================================================================\n",
    "# Identifying missing values\n",
    "# =============================================================================\n",
    "# To check the count of missing values present in each column\n",
    "churn1.isnull().sum()\n",
    "\n",
    "# Missing values in SeniorCitizen, MonthlyCharges, TotalCharges\n",
    "# =============================================================================\n",
    "# Imputing missing values\n",
    "# =============================================================================\n",
    "\"\"\" Two ways of approach\n",
    "\t - Fill the missing values by mean / median, in case of numerical variable\n",
    "\t - Fill the missing values with the class which has maximum count, in case of\n",
    "       categorical variable\n",
    "\"\"\"\n",
    "\n",
    "# ==================== Mode imputation - SeniorCitizen ========================\n",
    "\n",
    "churn1['SeniorCitizen'].fillna(churn1['SeniorCitizen'].mode()[0], inplace = True)\n",
    "\n",
    "churn1.SeniorCitizen.isnull().sum()\n",
    "\n",
    "###############################################################################\n",
    "# Look at the description to know whether numerical variables should be\n",
    "# imputed with mean or median\n",
    "\"\"\"\n",
    "    DataFrame.describe() - generates descriptive statistics that summarize the \n",
    "    central tendency, dispersion and shape of a dataset’s distribution,\n",
    "    excluding NaN values\n",
    "\"\"\"\n",
    "churn1.describe()\n",
    "# ==================== Mean imputation - TotalCharges ========================\n",
    "\n",
    "churn1['TotalCharges'].mean()\n",
    "\n",
    "sns.boxplot(x = churn1['TotalCharges'], y = churn1['Churn'])\n",
    "\n",
    "# Let us impute those missing values using mean based on the output\n",
    "# varieble 'Churn' – Yes & No\n",
    "\n",
    "churn1.groupby(['Churn']).mean().groupby('Churn')['TotalCharges'].mean()\n",
    "\n",
    "churn1['TotalCharges'] = churn1.groupby('Churn')['TotalCharges'] \\\n",
    "    .transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "churn1.TotalCharges.isnull().sum()\n",
    "\n",
    "\n",
    "# ==================== Mean imputation - MonthlyCharges ========================\n",
    "\n",
    "churn1['MonthlyCharges'].mean()\n",
    "\n",
    "sns.boxplot(x = churn1['MonthlyCharges'], y = churn1['Churn'])\n",
    "\n",
    "# Let us impute those missing values using mean based on the output\n",
    "# varieble 'Churn' – Yes & No\n",
    "\n",
    "churn1.groupby(['Churn']).mean().groupby('Churn')['MonthlyCharges'].mean()\n",
    "\n",
    "churn1['MonthlyCharges'] = churn1.groupby('Churn')['MonthlyCharges'] \\\n",
    "    .transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "churn1.MonthlyCharges.isnull().sum()\n",
    "\n",
    "###############################################################################\n",
    "# SAMPLING\n",
    "###############################################################################\n",
    "\n",
    "# =================== RANDOM SAMPLING -  WITHOUT REPLACEMENT ==================\n",
    "\n",
    "import random\n",
    "\n",
    "p1    = list(range(1, 20))\n",
    "print(p1)\n",
    "\n",
    "SRSWOR = random.sample(population = p1, k = 10)\n",
    "print(SRSWOR)\n",
    "\n",
    "# If the sample size i.e. k is larger than the popultaion p1, ValueError is raised.\n",
    "\n",
    "# =================== RANDOM SAMPLING -  WITH REPLACEMENT ==================\n",
    "\n",
    "p2 = list(range(1, 25))\n",
    "print(p2)\n",
    "\n",
    "SRSWR = random.choices(population = p2, k = 10)\n",
    "print(SRSWR)\n",
    "\n",
    "###############################################################################\n",
    "############################## MODULE OUTCOMES ################################\n",
    "###############################################################################\n",
    "#1. Importing from different formats\n",
    "#2. Joins in python\n",
    "#3. Basic descriptive analysis of data - to check the data type\n",
    "#4. Convert to valid data types\n",
    "#5. Consistency checks, unique values and regular expression patterns\n",
    "#6. Logical checks for outliers\n",
    "#7. Filling missing data- avg of all data, avg of data in categories, apply lambda\n",
    "#8. Outlier detection\n",
    "#9. Sampling (with/without replacement)\n",
    "\n",
    "###############################################################################\n",
    "############################### END OF SCRIPT #################################\n",
    "###############################################################################\n",
    "\n",
    "#%%\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@author: GITAA\n",
    "\"\"\"\n",
    "'''\n",
    "=============================================================================\n",
    " Pandas Dataframes\n",
    "    - Introduction to pandas\n",
    "    - Importing data into Spyder\n",
    "    - Creating copy of original data\n",
    "    - Attributes of data\n",
    "    - Indexing and selecting data\n",
    "    - Data types :Numeric & Character\n",
    "    - Checking data types of each column\n",
    "    - Count of unique data types\n",
    "    - Selecting data based on data types\n",
    "    - Concise summary of dataframe\n",
    "    - Checking format of each column\n",
    "    - Getting unique elements of each columns\n",
    "    - Converting variable’s data types\n",
    "    - Category vs Object data type\n",
    "    - Cleaning column ‘Doors\n",
    "    - Getting count of missing values\n",
    "    - Frequency tables\n",
    "    - Two-way tables\n",
    "    - Two-way table - joint probability\n",
    "    - Two-way table - marginal probability\n",
    "    - Two-way table - conditional probability\n",
    "    - Correlation\n",
    "    - Identifying missing values\n",
    "    - Approaches to fill the missing values\n",
    "=============================================================================\n",
    "'''\n",
    "# =============================================================================\n",
    "# Importing necessary libraries\n",
    "# =============================================================================\n",
    "import os               # ‘os’ library to change the working directory\n",
    "import pandas as pd     # ‘pandas’ library to work with dataframes\n",
    "import numpy as np      # ‘numpy’ library to perform numeric operations\n",
    "\n",
    "#os. chdir(\"D:\\Pandas\") # Changing the working directory\n",
    "\n",
    "# =============================================================================\n",
    "# Importing data\n",
    "# =============================================================================\n",
    "cars_data = pd.read_csv('Toyota.csv')\n",
    "\n",
    "# By passing 'index_col=0', first column becomes the index column\n",
    "cars_data = pd.read_csv('Toyota.csv', index_col=0)\n",
    "\n",
    "# =============================================================================\n",
    "# Creating copy of original data\n",
    "# =============================================================================\n",
    "'''\n",
    "In Python, there are two ways to create copies\n",
    " * Shallow copy :\n",
    " - It only creates a new variable that shares the reference of the original object\n",
    " - Any changes made to a copy of object will be reflected in the original object as well\n",
    " * Deep copy: \n",
    " - In case of deep copy, a copy of object is copied in other object with no \n",
    "   reference to the original\n",
    " - Any changes made to a copy of object will not be reflected in the original object\n",
    "'''\n",
    "# shallow copy\n",
    "samp = cars_data\n",
    "samp = cars_data.copy(deep=False)\n",
    "\n",
    "# deep copy\n",
    "cars_data1 = cars_data.copy()\n",
    "cars_data1 = cars_data.copy(deep=True)\n",
    "\n",
    "# =============================================================================\n",
    "# Attributes of data\n",
    "# =============================================================================\n",
    "cars_data1.index         # to get the index (row labels) of the dataframe\n",
    "cars_data1.columns       # to get the column labels of the dataframe\n",
    "cars_data1.size          # to get the total number of elements from the dataframe\n",
    "cars_data1.shape         # to get the dimensionality of the dataframe\n",
    "cars_data1.memory_usage()# to get the memory usage of each column in bytes\n",
    "cars_data1.ndim          # to get the number of axes / array dimensions\n",
    "# a two-dimensional array stores data in a format\n",
    "# consisting of rows and columns\n",
    "\n",
    "# =============================================================================\n",
    "# Indexing and selecting data\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    " - Python slicing operator ‘[ ]’ and attribute/ dot operator ‘. ’  are used \n",
    "   for indexing\n",
    " - Provides quick and easy access to pandas data structures\n",
    "\"\"\"\n",
    "cars_data1.head(6) # The function head returns the first n rows from the dataframe\n",
    "# By default, the head() returns first 5 rows\n",
    "\n",
    "cars_data1.tail(5) # The function tail returns the last n rows\n",
    "# for the object based on position\n",
    "\n",
    "\"\"\"\n",
    " -  To access a scalar value, the fastest way is to use the 'at' and 'iat' methods\n",
    " - 'at' provides label-based scalar lookups\n",
    " - 'iat' provides integer-based lookups \n",
    "\"\"\"\n",
    "cars_data1.at[4,'FuelType'] # value corresponds to 5th row & 'FuelType' column\n",
    "cars_data1.iat[5,6]         # value corresponds to 6th row & 7th column\n",
    "\n",
    "\"\"\"\n",
    "    To access a group of rows and columns by label(s) .loc[ ] can be used\n",
    "\"\"\"\n",
    "cars_data1.loc[:,'FuelType']\n",
    "# =============================================================================\n",
    "# Data types\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "    - The way information gets stored in a dataframe or a python object affects\n",
    "      the analysis and outputs of calculations\n",
    "    - There are two main types of data : numeric and character types\n",
    "    - Numeric data types includes integers and floats\n",
    "    - For example: integer – 10, float – 10.53    \n",
    "    - Strings are known as objects in pandas which can store values that contain\n",
    "    - numbers and / or characters\n",
    "    - For example: ‘category1’\n",
    "\"\"\"\n",
    "# =============================================================================\n",
    "# Checking data types of each column\n",
    "# =============================================================================\n",
    "cars_data1.dtypes             # returns a series with the data type of each column\n",
    "\n",
    "# =============================================================================\n",
    "# Count of unique data types\n",
    "# =============================================================================\n",
    "cars_data1.get_dtype_counts() # returns counts of unique data types in the dataframe\n",
    "\n",
    "# =============================================================================\n",
    "# Selecting data based on data types\n",
    "# =============================================================================\n",
    "cars_data1.select_dtypes(exclude=[object])\n",
    "# returns a subset of the columns from dataframe by excluding columns of object data\n",
    "\n",
    "# =============================================================================\n",
    "# Concise summary of dataframe\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "info() returns a concise summary of a dataframe\n",
    "    data type of index\n",
    "    data type of columns\n",
    "    count of non-null values \n",
    "    memory usage\n",
    "\"\"\"\n",
    "cars_data1.info()\n",
    "# =============================================================================\n",
    "# Checking format of each column\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "By using info(), we can see\n",
    "    - ‘KM’ has been read as object instead of integer\n",
    "    - ‘HP’ has been read as object instead of integer\n",
    "    - ‘MetColor’ and ‘Automatic’ have been read as float64 and int64 respectively\n",
    "       since it has values 0/1\n",
    "    - Ideally, ‘Doors’ should’ve been read as int64 since it has values 2, 3, 4, 5.\n",
    "      But it has been read as object\n",
    "    - Missing values present in few variables\n",
    "Let’s encounter the reason !\n",
    "\"\"\"\n",
    "# =============================================================================\n",
    "# Unique elements of columns\n",
    "# =============================================================================\n",
    "\"\"\" unique() is used to find the unique elements of a column \"\"\"\n",
    "\n",
    "print(np.unique(cars_data1['KM'])) # ‘KM’ has special character to it '??'\n",
    "# Hence, it has been read as object instead of int64\n",
    "\n",
    "print(np.unique(cars_data1['HP'])) # ‘HP’ has special character to it '????'\n",
    "# Hence, it has been read as object instead of int64\n",
    "\n",
    "print(np.unique(cars_data1['MetColor'])) # ‘MetColor’ have been read as float64\n",
    "#  since it has values 0. & 1.\n",
    "\n",
    "print(np.unique(cars_data1['Automatic']))# ‘Automatic’ has been read as int64\n",
    "#  since it has values 0 & 1\n",
    "\n",
    "print(np.unique(cars_data1['Doors']))    # ‘Doors’ has been read as object\n",
    "# instead of int64 because of values\n",
    "# ‘five’ ‘four’ ‘three’ which are strings\n",
    "\n",
    "# =============================================================================\n",
    "# Importing data (replacing special chars with nan values)\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "    - We need to know how missing values are represented in the dataset\n",
    "      in order to make reasonable decisions \n",
    "    - The missing values exist in the form of ‘nan’, '??', '????'\n",
    "    - Python, by default replace blank values with ‘nan’\n",
    "    - Now, importing the data considering other forms of missing values in a dataframe\n",
    "\"\"\"\n",
    "cars_data = pd.read_csv('Toyota.csv', index_col=0, na_values=[\"??\",\"????\"])\n",
    "\n",
    "cars_data.info() # Summary - after replacing special characters with nan\n",
    "\n",
    "# =============================================================================\n",
    "# Converting variable’s data types\n",
    "# =============================================================================\n",
    "\"\"\" astype() method is used to explicitly convert data types from one to another\"\"\"\n",
    "\n",
    "# Converting ‘MetColor’ , ‘Automatic’ to object data type\n",
    "\n",
    "cars_data['MetColor']  = cars_data['MetColor'].astype('object')\n",
    "cars_data['Automatic'] = cars_data['Automatic'].astype('object')\n",
    "\n",
    "# =============================================================================\n",
    "# category vs object data type\n",
    "# =============================================================================\n",
    "\"\"\" nbytes() is used to get the total bytes consumed by the elements of the columns\"\"\"\n",
    "\n",
    "# If ‘FuelType’ is of object data type,\n",
    "cars_data['FuelType'].nbytes                     # 11488\n",
    "\n",
    "# If ‘FuelType’ is of category data type,\n",
    "cars_data['FuelType'].astype('category').nbytes # 1460\n",
    "\n",
    "# Re-checking the data type of variables after all the conversions\n",
    "cars_data.info()\n",
    "\n",
    "# =============================================================================\n",
    "# Cleaning column ‘Doors’\n",
    "# =============================================================================\n",
    "# Checking unique values of variable ‘Doors’ :\n",
    "print(np.unique(cars_data['Doors']))\n",
    "\n",
    "\"\"\"\n",
    "    replace() is used to replace a value with the desired value \n",
    "    Syntax: DataFrame.replace([to_replace, value, …])\n",
    "\"\"\"\n",
    "\n",
    "cars_data['Doors'].replace('three',3,inplace=True)\n",
    "cars_data['Doors'].replace('four',4,inplace=True)\n",
    "cars_data['Doors'].replace('five',5,inplace=True)\n",
    "\n",
    "# To check the frequencies of unique cateogories in a variable\n",
    "cars_data['Doors'].value_counts()\n",
    "\n",
    "\"\"\"\n",
    "   (or) Pandas- where() \n",
    "\"\"\"\n",
    "cars_data['Doors'].where(cars_data['Doors']!='three',3,inplace=True)\n",
    "\n",
    "\"\"\" \n",
    "   (or) Numpy- where()\n",
    "\"\"\"\n",
    "cars_data['Doors'] = np.where(cars_data['Doors']=='five',5,cars_data['Doors'])\n",
    "\n",
    "# Converting ‘Doors’ to int64:\n",
    "cars_data['Doors'] = cars_data['Doors'].astype('int64')\n",
    "cars_data['Doors'].value_counts()\n",
    "\n",
    "# =============================================================================\n",
    "# To detect missing values\n",
    "# =============================================================================\n",
    "# To check the count of missing values present in each column Dataframe.isnull.sum() is used\n",
    "\n",
    "cars_data.isnull().sum()\n",
    "\n",
    "# =============================================================================\n",
    "#   Cross tables & Correlation\n",
    "# =============================================================================\n",
    "cars_data2 = cars_data.copy()\n",
    "\"\"\"\n",
    "    pandas.crosstab()\n",
    "    - To compute a simple cross-tabulation of one, two (or more) factors\n",
    "    - By default computes a frequency table of the factors \n",
    "\"\"\"\n",
    "# =============================================================================\n",
    "#     # One way table\n",
    "# =============================================================================\n",
    "\n",
    "pd.crosstab(index=cars_data2['FuelType'], columns='count', dropna=True)\n",
    "# Most of the cars have petrol as fuel type\n",
    "\n",
    "# =============================================================================\n",
    "#     # Two-way table\n",
    "# =============================================================================\n",
    "# To look at the frequency distribution of gearbox types with respect to different\n",
    "# fuel types of the cars\n",
    "\n",
    "pd.crosstab(index   = cars_data2['Automatic'],\n",
    "            columns = cars_data2['FuelType'],\n",
    "            dropna  = True)\n",
    "\n",
    "# =============================================================================\n",
    "#     # Two-way table with proportion / Joint probability\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "Joint probability is the likelihood of two independent events happening at the same time\n",
    "\"\"\"\n",
    "pd.crosstab(index     = cars_data2['Automatic'],\n",
    "            columns   = cars_data2['FuelType'],\n",
    "            normalize = True,\n",
    "            dropna    = True)\n",
    "\n",
    "# 0.82 => Joint probability of manual gear box and petrol fuel type\n",
    "\n",
    "# =============================================================================\n",
    "#     Two-way table - Marginal probability\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "Marginal probability is the probability of the occurrence of the single event\n",
    "\"\"\"\n",
    "pd.crosstab(index     = cars_data2['Automatic'],\n",
    "            columns   = cars_data2['FuelType'],\n",
    "            margins   = True,\n",
    "            dropna    = True,\n",
    "            normalize = True)\n",
    "\n",
    "# Probability of cars having manual gear box when the fuel type are\n",
    "# CNG or Diesel or Petrol is 0.95\n",
    "\n",
    "# =============================================================================\n",
    "#     Two-way table - Conditional probability=> Row sum = 1\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "Conditional probability is the probability of an event ( A ), given that \n",
    "another event ( B ) has already occurred\n",
    "\"\"\"\n",
    "pd.crosstab(index     = cars_data2['Automatic'],\n",
    "            columns   = cars_data2['FuelType'],\n",
    "            margins   = True,\n",
    "            dropna    = True,\n",
    "            normalize = 'index')\n",
    "\n",
    "# Given the gear box, probability of different fuel type\n",
    "\n",
    "# =============================================================================\n",
    "#     Two-way table - Conditional probability => Column sum =1\n",
    "# =============================================================================\n",
    "pd.crosstab(index     = cars_data2['Automatic'],\n",
    "            columns   = cars_data2['FuelType'],\n",
    "            margins   = True,\n",
    "            dropna    = True,\n",
    "            normalize = 'columns')\n",
    "\n",
    "# Given the fuel type, probability of different gear box\n",
    "\n",
    "# =============================================================================\n",
    "# Correlation\n",
    "# =============================================================================\n",
    "# Correlation: the strength of association between two variables\n",
    "\n",
    "# Excluding the categorical variables to find the correlation\n",
    "\n",
    "numerical_data = cars_data2.select_dtypes(exclude=[object])\n",
    "print(numerical_data.shape)\n",
    "\n",
    "# Finding the correlation between numerical variables\n",
    "corr_matrix = numerical_data.corr()\n",
    "print(corr_matrix)\n",
    "\n",
    "# Rounding off to two decimal places\n",
    "print(round(corr_matrix,2))\n",
    "\n",
    "# =============================================================================\n",
    "# Identifying missing values\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    " - In Pandas dataframes, missing data is represented by NaN\n",
    "  (an acronym for Not a Number)\n",
    " - To check null values in Pandas dataframes, isnull() and isna() are used\n",
    " - These functions returns a dataframe of Boolean values which are True for NaN values\n",
    "\"\"\"\n",
    "cars_data2 = cars_data.copy()\n",
    "cars_data3 = cars_data2.copy()\n",
    "\n",
    "# To check the count of missing values present in each column\n",
    "\n",
    "print('Data columns with null values:\\n')\n",
    "\n",
    "cars_data2.isna().sum()    #or\n",
    "cars_data2.isnull().sum()\n",
    "\n",
    "# Subsetting the rows that have one or more missing values\n",
    "missing = cars_data2[cars_data2.isnull().any(axis=1)]\n",
    "\n",
    "# =============================================================================\n",
    "# Imputing missing values\n",
    "# =============================================================================\n",
    "\"\"\" Two ways of approach\n",
    "\t - Fill the missing values by mean / median, in case of numerical variable\n",
    "\t - Fill the missing values with the class which has maximum count, in case of\n",
    "       categorical variable\n",
    "\"\"\"\n",
    "\n",
    "# Look at the description to know whether numerical variables should be\n",
    "# imputed with mean or median\n",
    "\"\"\"\n",
    "    DataFrame.describe() - generates descriptive statistics that summarize the \n",
    "    central tendency, dispersion and shape of a dataset’s distribution, excluding NaN values\n",
    "\"\"\"\n",
    "cars_data2.describe()\n",
    "cars_data2.describe(include=\"O\")\n",
    "cars_data2.describe(include=\"all\")\n",
    "\n",
    "\n",
    "# Mean and median of kilometer is far away\n",
    "# Therefore impute with median\n",
    "\n",
    "# ==================== Replacing 'Age' with mean ==============================\n",
    "cars_data2['Age'].mean()\n",
    "\n",
    "cars_data2['Age'].fillna(cars_data2['Age'].mean(), inplace = True)\n",
    "\n",
    "cars_data2['Age'].isnull().sum()\n",
    "\n",
    "# ==================== Replacing 'KM' with median ==============================\n",
    "cars_data2['KM'].median()\n",
    "\n",
    "cars_data2['KM'].fillna(cars_data2['KM'].median(), inplace = True)\n",
    "\n",
    "cars_data2['KM'].isnull().sum()\n",
    "\n",
    "# ==================== Replacing 'HP' with mean ==============================\n",
    "cars_data2['HP'].mean()\n",
    "\n",
    "cars_data2['HP'].fillna(cars_data2['HP'].mean(), inplace = True)\n",
    "\n",
    "cars_data2['HP'].isnull().sum()\n",
    "\n",
    "# Check for missing data after filling values\n",
    "cars_data2.isnull().sum()\n",
    "\n",
    "# ==================== Replacing 'Fuel Type' with mode ========================\n",
    "\"\"\"\n",
    "- Returns a Series containing counts of unique values\n",
    "- The values will be in descending order so that the first element is \n",
    "  the most frequently-occurring element\n",
    "- Excludes NA values by default\n",
    "\"\"\"\n",
    "cars_data2['FuelType'].value_counts()\n",
    "\n",
    "# To get the mode value of FuelType\n",
    "cars_data2['FuelType'].value_counts().index[0]\n",
    "\n",
    "# To fill NA/NaN values using the specified value\n",
    "cars_data2['FuelType'].fillna(cars_data2['FuelType'] \\\n",
    "                              .value_counts().index[0], \\\n",
    "                              inplace = True)\n",
    "\n",
    "cars_data2['FuelType'].isnull().sum()\n",
    "\n",
    "# ==================== Replacing 'MetColor' with mode ========================\n",
    "\n",
    "# To get the mode value of Metcolor\n",
    "cars_data2['MetColor'].mode()\n",
    "\n",
    "# To get categroy with maximum freq\n",
    "# Index 0 will get the category\n",
    "cars_data2['MetColor'].mode()[0]\n",
    "\n",
    "# replacing MetColor with mode\n",
    "cars_data2['MetColor'].fillna(cars_data2['MetColor'] \\\n",
    "                              .mode()[0], inplace = True)\n",
    "\n",
    "## Check for missing data after filling values\n",
    "cars_data2['MetColor'].isnull().sum()\n",
    "\n",
    "# Check for missing data after filling values\n",
    "cars_data2.isnull().sum()\n",
    "\n",
    "# ==================== Imputation using lambda functionss ========================\n",
    "\n",
    "# To fill the NA/ NaN values in both numerical and categorial variables at one stretch\n",
    "\n",
    "cars_data3 = cars_data3.apply(lambda x:x.fillna(x.value_counts().index[0]))\n",
    "cars_data3.isnull().sum()\n",
    "\n",
    "# Fill all numerical variables at a stretch\n",
    "cars_data3 = cars_data3.apply(lambda x:x.fillna(x.mean()))\n",
    "print('Data columns with null values:\\n', cars_data3.isnull().sum())\n",
    "\n",
    "# Fill numerical and categorial variables at one stretch\n",
    "\n",
    "cars_data3 = cars_data3.apply(lambda x:x.fillna(x.mean()) \\\n",
    "    if x.dtype=='float' else \\\n",
    "    x.fillna(x.value_counts().index[0]))\n",
    "\n",
    "print('Data columns with null values:\\n', cars_data3.isnull().sum())\n",
    "\n",
    "# =============================================================================\n",
    "# END OF SCRIPT\n",
    "# =============================================================================\n",
    "\n",
    "#%%\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Jun 12 14:20:21 2019\n",
    "\n",
    "@author: GITAA\n",
    "\"\"\"\n",
    "\n",
    "#=============================================================================\n",
    "# READING DATA\n",
    "#=============================================================================\n",
    "\n",
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "'''\n",
    "=============================================================================\n",
    " Reading .csv format data\n",
    "=============================================================================\n",
    "'''\n",
    "data_csv = pd.read_csv('Iris_data_sample.csv')\n",
    "\n",
    "# =============================================================================\n",
    "# Setting the 1st coulmn 'Unnamed: 0' as index column while reading data\n",
    "# =============================================================================\n",
    "data_csv = pd.read_csv('Iris_data_sample.csv',index_col=0)\n",
    "\n",
    "# =============================================================================\n",
    "# Replacing ‘??’ and ‘# # #’ as 'nan' values\n",
    "# =============================================================================\n",
    "\n",
    "data_csv = pd.read_csv('Iris_data_sample.csv',\n",
    "                       index_col=0,na_values=[\"??\"])\n",
    "\n",
    "data_csv = pd.read_csv('Iris_data_sample.csv',\n",
    "                       index_col=0,na_values=[\"??\",\"###\"])\n",
    "\n",
    "'''\n",
    "=============================================================================\n",
    "Reading .xlsx format data\n",
    "=============================================================================\n",
    "'''\n",
    "data_xlsx = pd.read_excel('Iris_data_sample.xlsx',\n",
    "                          sheet_name='Iris_data')\n",
    "\n",
    "data_xlsx = pd.read_excel('Iris_data_sample.xlsx',index_col=0)\n",
    "\n",
    "data_xlsx = pd.read_excel('Iris_data_sample.xlsx',\n",
    "                          index_col=0,\n",
    "                          na_values=[\"??\",\"###\"])\n",
    "'''\n",
    "=============================================================================\n",
    "Reading .txt format data\n",
    "=============================================================================\n",
    "\n",
    " - Delimitor can be a space or a tab               \n",
    " - Try out to see what works  \n",
    "'''\n",
    "\n",
    "data_txt1 = pd.read_table('Iris_data_sample.txt',delimiter=\"\\t\")\n",
    "data_txt1 = pd.read_table('Iris_data_sample.txt',delimiter=\",\")\n",
    "data_txt1 = pd.read_table('Iris_data_sample.txt',delimiter=\" \") # correct\n",
    "\n",
    "#Instead of using read_table(), read_csv() can also be used to read .txt files\n",
    "data_txt2 = pd.read_csv('Iris_data_sample.txt',delimiter=\" \")\n",
    "\n",
    "# =============================================================================\n",
    "#   END OF SCRIPT\n",
    "# =============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f799e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@author: GITAA\n",
    "\"\"\"\n",
    "'''\n",
    "    Basic plots using matplotlib library:\n",
    "    - Scatter plot\n",
    "    - Histogram\n",
    "    - Bar plot\n",
    "    Basic plots using seaborn library:\n",
    "    - Scatter plot\n",
    "    - Histogram\n",
    "    - Bar plot\n",
    "    - Box and whiskers plot\n",
    "    - Pairwise plots\n",
    "'''\n",
    "# =============================================================================\n",
    "# Importing necessary libraries\n",
    "# =============================================================================\n",
    "import os               # ‘os’ library to change the working directory\n",
    "import pandas as pd     # ‘pandas’ library to work with dataframes\n",
    "import numpy as np      # ‘numpy’ library to perform numeric operations\n",
    "import matplotlib.pyplot as plt # to visualize the data\n",
    "import seaborn as sns   # to visualize the data\n",
    "# =============================================================================\n",
    "# Importing data (replacing special chars with nan values)\n",
    "# =============================================================================\n",
    "\n",
    "cars_data = pd.read_csv('Toyota.csv', index_col=0, na_values=[\"??\",\"????\"])\n",
    "\n",
    "# Removing missing values from the dataframe\n",
    "cars_data.dropna(axis = 0, inplace=True)\n",
    "\n",
    "# =============================================================================\n",
    "# SCATTER PLOT - MATPLOTLIB\n",
    "# =============================================================================\n",
    "\n",
    "plt.scatter(cars_data['Age'], cars_data['Price'], c  ='red', )\n",
    "plt.title('Scatter PLot')\n",
    "plt.xlabel('Age (months)')\n",
    "plt.ylabel('Price (Euros)')\n",
    "plt.show() \n",
    "\n",
    "#The price of the car decreases as age of the car increases\n",
    "\n",
    "# =============================================================================\n",
    "#  HISTOGRAM - MATPLOTLIB\n",
    "# =============================================================================\n",
    "# Histogram with default arguments\n",
    "plt.hist(cars_data['KM']) \n",
    "\n",
    "plt.hist(cars_data['KM'], color = 'red', edgecolor = 'white', bins =5)\n",
    "\"\"\"\n",
    "Frequency distribution of kilometre of the cars shows that most of the cars have\n",
    "travelled between 50000 – 100000 km and there are only few cars with more distance travelled\n",
    "\"\"\"\n",
    "# for any bin value, the minor tick lables remains the same\n",
    "# only the no.of bars changes\n",
    "\n",
    "# histogram for the given range of values\n",
    "plt.hist(cars_data['KM'], color='blue', edgecolor='white', bins=10, range=(5000,15000))\n",
    "plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# BAR PLOT - MATPLOTLIB\n",
    "# =============================================================================\n",
    "\n",
    "counts   = [979, 120, 12]\n",
    "fuelType = ('Petrol', 'Diesel', 'CNG')  # Set the labels of the xticks\n",
    "index    = np.arange(len(fuelType))     # Set the location of the xticks\n",
    "\n",
    "plt.bar(index, counts, color=['red', 'blue', 'cyan'], edgecolor='darkblue')\n",
    "plt.title('Frequency plot of FuelType')\n",
    "plt.xlabel('Fuel Type')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(index, fuelType,rotation = 90)\n",
    "plt.show()\n",
    "\n",
    "\"\"\"\n",
    "Bar plot of fuel type shows that most of the cars have petrol as fuel type\n",
    "\"\"\" \n",
    "# =============================================================================\n",
    "# SACTTER PLOT - SEABORN\n",
    "# =============================================================================\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "#1. Scatter plot of Price vs Age with default arguments\n",
    "sns.regplot(x=cars_data['Price'], y=cars_data['Age'])\n",
    "\n",
    "# By default, fit_reg = True \n",
    "# It estimates and plots a regression model relating the x and y variables\n",
    " \n",
    "# 2. Scatter plot of Price vs Age without the regression fit line\n",
    "sns.regplot(x=cars_data['Price'], y=cars_data['Age'], fit_reg=False)\n",
    "\n",
    "# 3. Scatter plot of Price vs Age by customizing the appearance of markers\n",
    "sns.regplot(x=cars_data['Price'], y=cars_data['Age'], marker=\"*\", fit_reg=False)\n",
    "sns.plt.show()\n",
    "#%%\n",
    "sns.regplot(x=cars_data['Price'], y=cars_data['Age'], \n",
    "            marker=\"o\", fit_reg=False,\n",
    "            scatter_kws={\"color\":\"green\",\"alpha\":0.3,\"s\":200} )\n",
    "sns.plt.show()\n",
    "#%%\n",
    "# 4. Scatter plot of Price vs Age by FuelType\n",
    "# Using hue parameter, including another variable to show the fuel types \n",
    "# categories with different colors\n",
    "\n",
    "sns.lmplot(x = 'Age', y = 'Price', data = cars_data, fit_reg = False,\n",
    "           hue = 'FuelType', legend = True, palette=\"Set1\")\n",
    "sns.plt.show()\n",
    "#%%\n",
    "# 4. Differentiating categories using markers\n",
    "sns.lmplot(x = 'Age', y = 'Price', data = cars_data, fit_reg = False,\n",
    "           hue = 'FuelType', legend = True, markers=[\"o\", \"x\", \"1\"])\n",
    "sns.plt.show() \n",
    "#%%\n",
    "\n",
    "# =============================================================================\n",
    "# HISTOGRAM - SEABORN\n",
    "# =============================================================================\n",
    "# 1.Histogram of Age with default kernel density estimate \n",
    "sns.distplot(cars_data['Age'] )\n",
    "#%%\n",
    "# 2. Histogram without kernel density estimate\n",
    "sns.distplot(cars_data['Age'], hist=True, kde=False)\n",
    "#%%\n",
    "# 3. Histogram with fixed no. of bins\n",
    "sns.distplot(cars_data['Age'], bins=5 )\n",
    "#%%\n",
    "\n",
    "# =============================================================================\n",
    "# BAR PLOT - SEABORN\n",
    "# =============================================================================\n",
    "\n",
    "# Frequency distribution of fuel type of the cars\n",
    "sns.countplot(x=\"FuelType\", data=cars_data)\n",
    "\n",
    "# Grouped bar plot of FuelType and Automatic\n",
    "sns.countplot(x=\"FuelType\", data=cars_data, hue = \"Automatic\")\n",
    "\n",
    "sns.countplot(y=\"FuelType\", data=cars_data, hue = \"Automatic\")\n",
    "\n",
    "sns.countplot(x=\"FuelType\", data=cars_data, palette=\"Set2\")\n",
    "\n",
    "# =============================================================================\n",
    "# Box and whiskers plot\n",
    "# =============================================================================\n",
    "# 1. Box plot for a numerical varaible\n",
    "#    Box and whiskers plot of Price to visually interpret the five-number summary\n",
    "\n",
    "sns.boxplot(y=cars_data[\"Price\"] )\n",
    "\n",
    "#2. Box and whiskers plot for numerical vs categorical variable \n",
    "#   Price of the cars for various fuel types \n",
    "\n",
    "sns.boxplot(x = cars_data['FuelType'], y = cars_data[\"Price\"])\n",
    "\n",
    "#3. Box plot for multiple numerical varaibles\n",
    "sns.boxplot(data = cars_data.ix[:,0:4])\n",
    "\n",
    "#4. Grouped box and whiskers plot of Price vs FuelType and Automatic\n",
    "\n",
    "sns.boxplot(x=\"FuelType\",  y = cars_data[\"Price\"], \n",
    "            hue=\"Automatic\", data=cars_data, palette=\"Set2\")\n",
    "\n",
    "# =============================================================================\n",
    "# Box-whiskers plot and Histogram\n",
    "# =============================================================================\n",
    "\n",
    "# Let’s plot box-whiskers plot and histogram on the same window\n",
    "# Split the plotting window into 2 parts \n",
    "\n",
    "f, (ax_box, ax_hist) = plt.subplots(2, sharex=True, gridspec_kw={\"height_ratios\": (.15, .85)})\n",
    " \n",
    "# Now, create two plots\n",
    "sns.boxplot(cars_data[\"Price\"], ax=ax_box)\n",
    "sns.distplot(cars_data[\"Price\"], ax=ax_hist, kde = False)\n",
    " \n",
    "# Remove x axis name for the boxplot\n",
    "ax_box.set(xlabel='')\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# END OF SCRIPT\n",
    "# =============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbc4f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@author: GITAA\n",
    "\"\"\"\n",
    "# =============================================================================\n",
    "# DATA PREPARATION\n",
    "# =============================================================================\n",
    "\n",
    "#%%\n",
    "# To work with dataframes\n",
    "import pandas as pd \n",
    "\n",
    "# To perform numerical operations\n",
    "import numpy as np\n",
    "\n",
    "#%%\n",
    "# Importing data \n",
    "\n",
    "demoDetails    =  pd.read_csv(\"demoDetails.csv\"   , index_col=0)\n",
    "acDetails      =  pd.read_csv(\"acDetails.txt\"     , sep=\"\\t\")\n",
    "serviceDetails =  pd.read_csv(\"serviceDetails.csv\", index_col=0)\n",
    "\n",
    "# By setting 'index_col = 0', 1st column will be the index column\n",
    "\n",
    "#%%\n",
    "# Data Wrangling\n",
    "\"\"\"\n",
    " - We are interested in merging acDetails, demoDetails and serviceDetails \n",
    " - Before merging we need to make necessary checks !\n",
    " - What are the mandatory checks you should look for before merging ?\n",
    " -   1. Are there any duplicate records?\n",
    "     2. Whether the customer ID is common across all the files ?\n",
    "\"\"\"\n",
    "\n",
    "# 1. Are there any duplicate records?\n",
    "\n",
    "len(np.unique(demoDetails['customerID']))\n",
    "\n",
    "len(np.unique(acDetails['customerID']))\n",
    "\n",
    "len(np.unique(serviceDetails['customerID']))\n",
    "\n",
    "# Yes, there is one duplicate record across all the three dataframes\n",
    "\n",
    "#%%\n",
    "# ======================== Determining duplicate records =================================\n",
    "\n",
    "# To determine the duplicate records 'duplicated()' can be used\n",
    "\n",
    "demoDetails.duplicated(subset=['customerID'], keep=False)\n",
    "\n",
    "# duplicated function returns a Boolean Series with True value \n",
    "# for each duplicated row\n",
    "\n",
    "# So now let's subset the rows and look at the duplications\n",
    "\n",
    "demoDetails[demoDetails.duplicated(['customerID'],keep=False)]\n",
    "\n",
    "acDetails[acDetails.duplicated(['customerID'],keep=False)]\n",
    "\n",
    "serviceDetails[serviceDetails.duplicated(['customerID'],keep=False)]\n",
    "\n",
    "#%%\n",
    "# ====================== Removing duplicate records ================================\n",
    "\n",
    "demoDetails    =  demoDetails.drop_duplicates() \n",
    "\n",
    "acDetails      =  acDetails.drop_duplicates()\n",
    "\n",
    "serviceDetails =  serviceDetails.drop_duplicates()\n",
    "\n",
    "# First occurrence of the duplicate row is kept and \n",
    "# subsequent occurrence have been removed\n",
    "\n",
    "#%%\n",
    "\n",
    "# 2. Whether the customer ID is common across all the files ?\n",
    "\n",
    "# syntax: dataframe1.equals(dataframe2)\n",
    "\n",
    "acDetails.customerID.equals(demoDetails.customerID)\n",
    "\n",
    "serviceDetails.customerID.equals (demoDetails.customerID)\n",
    "\n",
    "acDetails.customerID.equals (serviceDetails.customerID)\n",
    "\n",
    "# Looks like they are indeed identical!\n",
    "\n",
    "#%% \n",
    "# ====================== Joining three dataframes =============================\n",
    "\n",
    "# Syntax: pd.merge(df1, df2, on=['Column_Name'], how='inner')\n",
    "\n",
    "churn  =  pd.merge(demoDetails, acDetails, on = \"customerID\")\n",
    "\n",
    "churn  =  pd.merge(churn,serviceDetails,   on = \"customerID\")\n",
    "\n",
    "churn1 =  churn.copy()\n",
    "\n",
    "#%%\n",
    "# ============ Data Exploration / Understanding the data ======================\n",
    "\n",
    "churn1.info()\n",
    "\n",
    "\"\"\" Points to note:\n",
    "-'tenure' has been read as object instead of integer\n",
    "-'SeniorCitizen' has been read as float64 instead of object\n",
    "- Missing values present in few variables\n",
    "\"\"\"\n",
    "# unique() finds the unique elements of an array\n",
    "np.unique(churn1['tenure'], return_counts = True )\n",
    "\n",
    "# 'tenure' has been read as object instead of integer \n",
    "# because of values One/Four which are strings\n",
    "\n",
    "np.unique(churn1['SeniorCitizen'])\n",
    "\n",
    "# 'SeniorCitizen' has been read as float64 instead of int64 since it has values nan values\n",
    "\n",
    "# Checking frequencies of each categories in a variable\n",
    "\n",
    "categotical_data = churn1.select_dtypes(include=['object']).copy()\n",
    "\n",
    "categotical_data.columns\n",
    "\n",
    "categotical_data['gender'].value_counts() \n",
    "\n",
    "# categotical_data.value_counts() AttributeError:\n",
    "\n",
    "categotical_data = categotical_data.drop(['customerID','tenure'],axis = 1)\n",
    "\n",
    "frequencies      = categotical_data.apply(lambda x: x.value_counts()).T.stack()\n",
    "\n",
    "print(frequencies)\n",
    "\n",
    "\"\"\" Points to note:\n",
    "- 'Dependents' should have only 2 levels (Yes/No) but it has 3 due \n",
    "-  the special character '1@#' that has been read as another level\n",
    "\"\"\"\n",
    "# Summary of numerical variables\n",
    "\n",
    "summary = churn1.describe()\n",
    "\n",
    "print(summary)\n",
    "\n",
    "#%%\n",
    "# ======================================== Data Cleaning ======================\n",
    "\n",
    "# Cleaning column 'tenure'\n",
    "\n",
    "# Replacing 'Four' by 4 and 'One' by 1 in 'tenure'\n",
    "    \n",
    "churn1['tenure'] = churn1.tenure.replace(\"Four\", 4)\n",
    "\n",
    "churn1['tenure'] = churn1.tenure.replace(\"One\", 1) \n",
    "\n",
    "churn1['tenure'] = churn1.tenure.astype(int)\n",
    "\n",
    "print(churn1['tenure'])\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "# Cleaning column 'Dependents'\n",
    "\"\"\" 'Dependents' should have only 2 levels (Yes/No) but it has 3 due \n",
    "     the special character '1@#' that has been read as another level\"\"\"\n",
    "     \n",
    "# Gives counts- class 'No' has the max count \n",
    "\n",
    "pd.crosstab(index=churn1['Dependents'], columns=\"count\")\n",
    "\n",
    "# Replacing \"1@#\" with 'No'   \n",
    "\n",
    "churn1['Dependents'] = churn1['Dependents'].replace(\"1@#\", 'No')\n",
    "      \n",
    "# Verifying if the special characters were converted to desired class\n",
    "\n",
    "table_dependents  = pd.crosstab(index = churn1['Dependents'], columns=\"count\")\n",
    "\n",
    "print(table_dependents) \n",
    "\n",
    "#%%\n",
    "\"\"\"\n",
    "    - Checking for logical fallacies in the data\n",
    "    - Approaches to resolve the logical fallacies in the data\n",
    "    - Outlier detection using boxplot\n",
    "    - Approaches to fill in missing values    \n",
    "\"\"\"\n",
    "############################### Logical Checks ################################\n",
    "# 1. Checking if the 'customerID' is consistent\n",
    "\n",
    "print(churn1['customerID'])\n",
    "\n",
    "\"\"\"\n",
    "I  Interms of total number of characters\n",
    "II Sequence of charaters i.e. first 4 characters of customerID should be \n",
    "    numbers followed by hyphen and 5 upper case letters\n",
    "    \n",
    "\"\"\"\n",
    "# I\n",
    "# to get the index of customerID whose length != 10\n",
    "len_ind = [i for i,value in enumerate(churn1.customerID) if len(value)!=10]\n",
    "\n",
    "import re \n",
    "pattern = '^[0-9]{4,4}-[A-Z]{5,5}'  \n",
    " \n",
    "p = re.compile(pattern)\n",
    "type(p)\n",
    "\n",
    "q = [i for i,value in enumerate(churn1.customerID) if p.match(str(value))==None]\n",
    "print(q)\n",
    "\n",
    "fp1 = re.compile('^[A-Z]{5,5}-[0-9]{4,4}')\n",
    "fp2 = re.compile('^[0-9]{4,4}/[A-Z]{5,5}')\n",
    "\n",
    "for i in q:\n",
    "    false_str = str(churn1.customerID[i])\n",
    "    if(fp1.match(false_str)):\n",
    "        str_splits=false_str.split('-')\n",
    "        churn1.customerID[i]=str_splits[1]+'-'+str_splits[0]\n",
    "    elif(fp2.match(false_str)):\n",
    "        churn1.customerID[i]=false_str.replace('/','-')\n",
    "\n",
    "#%%\n",
    "#################################################################################\n",
    "# Logical checks - check for fallacies in the data\n",
    "# If Internet service = No, then all the allied services related to internet \n",
    "# should be no. \n",
    "        \n",
    "# Is that the case?\n",
    "\n",
    "# Subsetting Internet Service and allied services\n",
    "y = churn1[(churn1.InternetService =='No')]\n",
    "z = y.iloc[:,13:20]\n",
    "\n",
    "\"\"\"\n",
    "   Some observations have InterService= No and Yes in certain allied services\n",
    "   This is a logical fallacy!\n",
    "   Two ways of approach:\n",
    "   => Brute force method- wherever InternetService = No, blindly make other \n",
    "      related fields 'No'\n",
    "   => Logical approach- If there are say 2 or more Yes in the allied services,\n",
    "      then go back and change InternetService= Yes \n",
    "                       else change the allied services = No\n",
    "\"\"\"\n",
    "# Logical approach\n",
    "\n",
    "for i,row in z.iterrows():\n",
    "    yes_cnt=row.str.count('Yes').sum()\n",
    "    if(yes_cnt>=2):\n",
    "        z.loc[i].InternetService='Yes'\n",
    "    else:\n",
    "        z.loc[i,:]='No internet service'\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# OUTLIER DETECTION\n",
    "###############################################################################\n",
    "\n",
    "## looking for any outliers\n",
    "churn1.tenure.describe()\n",
    "\n",
    "# Outlier detection using boxplot\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.boxplot(y = churn1['tenure'])\n",
    "\n",
    "# Replacing outliers by median of column 'tenure'\n",
    "churn1['tenure'] = np.where(churn1['tenure']>=500,\n",
    "      churn1['tenure'].median(), churn1['tenure'])\n",
    "\n",
    "# Checking the summary of the column 'tenure’ after median imputation\n",
    "churn1['tenure'].describe()\n",
    "sns.boxplot(y = churn1['tenure'])\n",
    "\n",
    "# =============================================================================\n",
    "# Identifying missing values\n",
    "# =============================================================================\n",
    "# To check the count of missing values present in each column \n",
    "churn1.isnull().sum()\n",
    "\n",
    "# Missing values in SeniorCitizen, MonthlyCharges, TotalCharges\n",
    "# =============================================================================\n",
    "# Imputing missing values\n",
    "# =============================================================================\n",
    "\"\"\" Two ways of approach\n",
    "\t - Fill the missing values by mean / median, in case of numerical variable\n",
    "\t - Fill the missing values with the class which has maximum count, in case of\n",
    "       categorical variable\n",
    "\"\"\"\n",
    "\n",
    "# ==================== Mode imputation - SeniorCitizen ========================\n",
    "\n",
    "churn1['SeniorCitizen'].fillna(churn1['SeniorCitizen'].mode()[0], inplace = True)\n",
    "\n",
    "churn1.SeniorCitizen.isnull().sum()\n",
    "\n",
    "###############################################################################\n",
    "# Look at the description to know whether numerical variables should be \n",
    "# imputed with mean or median\n",
    "\"\"\"\n",
    "    DataFrame.describe() - generates descriptive statistics that summarize the \n",
    "    central tendency, dispersion and shape of a dataset’s distribution,\n",
    "    excluding NaN values\n",
    "\"\"\"\n",
    "churn1.describe()\n",
    "# ==================== Mean imputation - TotalCharges ========================\n",
    "\n",
    "churn1['TotalCharges'].mean()\n",
    "\n",
    "sns.boxplot(x = churn1['TotalCharges'], y = churn1['Churn'])\n",
    "\n",
    "# Let us impute those missing values using mean based on the output\n",
    "# varieble 'Churn' – Yes & No\n",
    "\n",
    "churn1.groupby(['Churn']).mean().groupby('Churn')['TotalCharges'].mean()\n",
    "\n",
    "churn1['TotalCharges'] = churn1.groupby('Churn')['TotalCharges']\\\n",
    ".transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "churn1.TotalCharges.isnull().sum()\n",
    "\n",
    "\n",
    "# ==================== Mean imputation - MonthlyCharges ========================\n",
    "\n",
    "churn1['MonthlyCharges'].mean()\n",
    "\n",
    "sns.boxplot(x = churn1['MonthlyCharges'], y = churn1['Churn'])\n",
    "\n",
    "# Let us impute those missing values using mean based on the output\n",
    "# varieble 'Churn' – Yes & No\n",
    "\n",
    "churn1.groupby(['Churn']).mean().groupby('Churn')['MonthlyCharges'].mean()\n",
    "\n",
    "churn1['MonthlyCharges'] = churn1.groupby('Churn')['MonthlyCharges']\\\n",
    ".transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "churn1.MonthlyCharges.isnull().sum()\n",
    "\n",
    "###############################################################################\n",
    "# SAMPLING\n",
    "###############################################################################\n",
    "\n",
    "# =================== RANDOM SAMPLING -  WITHOUT REPLACEMENT ==================\n",
    " \n",
    "import random\n",
    "\n",
    "p1    = list(range(1, 20))\n",
    "print(p1)\n",
    "\n",
    "SRSWOR = random.sample(population = p1, k = 10)\n",
    "print(SRSWOR)\n",
    "\n",
    "# If the sample size i.e. k is larger than the popultaion p1, ValueError is raised.\n",
    "\n",
    "# =================== RANDOM SAMPLING -  WITH REPLACEMENT ==================\n",
    "\n",
    "p2 = list(range(1, 25))\n",
    "print(p2)\n",
    "\n",
    "SRSWR = random.choices(population = p2, k = 10)\n",
    "print(SRSWR)\n",
    "\n",
    "###############################################################################\n",
    "############################## MODULE OUTCOMES ################################\n",
    "###############################################################################\n",
    "#1. Importing from different formats                                          \n",
    "#2. Joins in python                                                           \n",
    "#3. Basic descriptive analysis of data - to check the data type               \n",
    "#4. Convert to valid data types                                               \n",
    "#5. Consistency checks, unique values and regular expression patterns         \n",
    "#6. Logical checks for outliers                                               \n",
    "#7. Filling missing data- avg of all data, avg of data in categories, apply lambda                                                               \n",
    "#8. Outlier detection  \n",
    "#9. Sampling (with/without replacement)                                                       \n",
    "                       \n",
    "###############################################################################\n",
    "############################### END OF SCRIPT #################################\n",
    "###############################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5466754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@author: GITAA\n",
    "\"\"\"\n",
    "'''\n",
    "=============================================================================\n",
    " Pandas Dataframes\n",
    "    - Introduction to pandas\n",
    "    - Importing data into Spyder\n",
    "    - Creating copy of original data\n",
    "    - Attributes of data\n",
    "    - Indexing and selecting data\n",
    "    - Data types :Numeric & Character\n",
    "    - Checking data types of each column\n",
    "    - Count of unique data types\n",
    "    - Selecting data based on data types\n",
    "    - Concise summary of dataframe\n",
    "    - Checking format of each column\n",
    "    - Getting unique elements of each columns\n",
    "    - Converting variable’s data types\n",
    "    - Category vs Object data type\n",
    "    - Cleaning column ‘Doors\n",
    "    - Getting count of missing values\n",
    "    - Frequency tables\n",
    "    - Two-way tables\n",
    "    - Two-way table - joint probability\n",
    "    - Two-way table - marginal probability\n",
    "    - Two-way table - conditional probability\n",
    "    - Correlation\n",
    "    - Identifying missing values\n",
    "    - Approaches to fill the missing values\n",
    "=============================================================================\n",
    "'''\n",
    "# =============================================================================\n",
    "# Importing necessary libraries\n",
    "# =============================================================================\n",
    "import os               # ‘os’ library to change the working directory\n",
    "import pandas as pd     # ‘pandas’ library to work with dataframes\n",
    "import numpy as np      # ‘numpy’ library to perform numeric operations\n",
    "\n",
    "#os. chdir(\"D:\\Pandas\") # Changing the working directory\n",
    "\n",
    "# =============================================================================\n",
    "# Importing data \n",
    "# =============================================================================\n",
    "cars_data = pd.read_csv('Toyota.csv')\n",
    "\n",
    "# By passing 'index_col=0', first column becomes the index column\n",
    "cars_data = pd.read_csv('Toyota.csv', index_col=0)\n",
    "\n",
    "# =============================================================================\n",
    "# Creating copy of original data\n",
    "# =============================================================================\n",
    "'''\n",
    "In Python, there are two ways to create copies\n",
    " * Shallow copy :\n",
    " - It only creates a new variable that shares the reference of the original object\n",
    " - Any changes made to a copy of object will be reflected in the original object as well\n",
    " * Deep copy: \n",
    " - In case of deep copy, a copy of object is copied in other object with no \n",
    "   reference to the original\n",
    " - Any changes made to a copy of object will not be reflected in the original object\n",
    "'''\n",
    "# shallow copy  \n",
    "samp = cars_data                     \n",
    "samp = cars_data.copy(deep=False)   \n",
    "\n",
    "# deep copy \n",
    "cars_data1 = cars_data.copy()      \n",
    "cars_data1 = cars_data.copy(deep=True)\n",
    "\n",
    "# =============================================================================\n",
    "# Attributes of data\n",
    "# =============================================================================\n",
    "cars_data1.index         # to get the index (row labels) of the dataframe\n",
    "cars_data1.columns       # to get the column labels of the dataframe\n",
    "cars_data1.size          # to get the total number of elements from the dataframe\n",
    "cars_data1.shape         # to get the dimensionality of the dataframe\n",
    "cars_data1.memory_usage()# to get the memory usage of each column in bytes\n",
    "cars_data1.ndim          # to get the number of axes / array dimensions\n",
    "                         # a two-dimensional array stores data in a format\n",
    "                         # consisting of rows and columns\n",
    "\n",
    "# =============================================================================\n",
    "# Indexing and selecting data\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    " - Python slicing operator ‘[ ]’ and attribute/ dot operator ‘. ’  are used \n",
    "   for indexing\n",
    " - Provides quick and easy access to pandas data structures\n",
    "\"\"\"\n",
    "cars_data1.head(6) # The function head returns the first n rows from the dataframe\n",
    "                   # By default, the head() returns first 5 rows\n",
    "                  \n",
    "cars_data1.tail(5) # The function tail returns the last n rows \n",
    "                   # for the object based on position\n",
    "\n",
    "\"\"\"\n",
    " -  To access a scalar value, the fastest way is to use the 'at' and 'iat' methods\n",
    " - 'at' provides label-based scalar lookups\n",
    " - 'iat' provides integer-based lookups \n",
    "\"\"\"\n",
    "cars_data1.at[4,'FuelType'] # value corresponds to 5th row & 'FuelType' column\n",
    "cars_data1.iat[5,6]         # value corresponds to 6th row & 7th column\n",
    "\n",
    "\"\"\"\n",
    "    To access a group of rows and columns by label(s) .loc[ ] can be used\n",
    "\"\"\"\n",
    "cars_data1.loc[:,'FuelType'] \n",
    "# =============================================================================\n",
    "# Data types\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "    - The way information gets stored in a dataframe or a python object affects\n",
    "      the analysis and outputs of calculations\n",
    "    - There are two main types of data : numeric and character types\n",
    "    - Numeric data types includes integers and floats\n",
    "    - For example: integer – 10, float – 10.53    \n",
    "    - Strings are known as objects in pandas which can store values that contain\n",
    "    - numbers and / or characters\n",
    "    - For example: ‘category1’\n",
    "\"\"\"\n",
    "# =============================================================================\n",
    "# Checking data types of each column\n",
    "# =============================================================================\n",
    "cars_data1.dtypes             # returns a series with the data type of each column\n",
    "\n",
    "# =============================================================================\n",
    "# Count of unique data types\n",
    "# =============================================================================\n",
    "cars_data1.get_dtype_counts() # returns counts of unique data types in the dataframe\n",
    "\n",
    "# =============================================================================\n",
    "# Selecting data based on data types\n",
    "# =============================================================================\n",
    "cars_data1.select_dtypes(exclude=[object])\n",
    "# returns a subset of the columns from dataframe by excluding columns of object data \n",
    "\n",
    "# =============================================================================\n",
    "# Concise summary of dataframe\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "info() returns a concise summary of a dataframe\n",
    "    data type of index\n",
    "    data type of columns\n",
    "    count of non-null values \n",
    "    memory usage\n",
    "\"\"\"\n",
    "cars_data1.info()\n",
    "# =============================================================================\n",
    "# Checking format of each column\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "By using info(), we can see\n",
    "    - ‘KM’ has been read as object instead of integer\n",
    "    - ‘HP’ has been read as object instead of integer\n",
    "    - ‘MetColor’ and ‘Automatic’ have been read as float64 and int64 respectively\n",
    "       since it has values 0/1\n",
    "    - Ideally, ‘Doors’ should’ve been read as int64 since it has values 2, 3, 4, 5.\n",
    "      But it has been read as object\n",
    "    - Missing values present in few variables\n",
    "Let’s encounter the reason !\n",
    "\"\"\"\n",
    "# =============================================================================\n",
    "# Unique elements of columns\n",
    "# =============================================================================\n",
    "\"\"\" unique() is used to find the unique elements of a column \"\"\"\n",
    "\n",
    "print(np.unique(cars_data1['KM'])) # ‘KM’ has special character to it '??'  \n",
    "                                   # Hence, it has been read as object instead of int64\n",
    "                                   \n",
    "print(np.unique(cars_data1['HP'])) # ‘HP’ has special character to it '????'   \n",
    "                                   # Hence, it has been read as object instead of int64\n",
    "                                   \n",
    "print(np.unique(cars_data1['MetColor'])) # ‘MetColor’ have been read as float64\n",
    "                                         #  since it has values 0. & 1.\n",
    "\n",
    "print(np.unique(cars_data1['Automatic']))# ‘Automatic’ has been read as int64\n",
    "                                         #  since it has values 0 & 1\n",
    "                                         \n",
    "print(np.unique(cars_data1['Doors']))    # ‘Doors’ has been read as object \n",
    "                                         # instead of int64 because of values \n",
    "                                         # ‘five’ ‘four’ ‘three’ which are strings\n",
    "\n",
    "# =============================================================================\n",
    "# Importing data (replacing special chars with nan values)\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "    - We need to know how missing values are represented in the dataset\n",
    "      in order to make reasonable decisions \n",
    "    - The missing values exist in the form of ‘nan’, '??', '????'\n",
    "    - Python, by default replace blank values with ‘nan’\n",
    "    - Now, importing the data considering other forms of missing values in a dataframe\n",
    "\"\"\"\n",
    "cars_data = pd.read_csv('Toyota.csv', index_col=0, na_values=[\"??\",\"????\"])\n",
    "\n",
    "cars_data.info() # Summary - after replacing special characters with nan\n",
    "\n",
    "# =============================================================================\n",
    "# Converting variable’s data types\n",
    "# =============================================================================\n",
    "\"\"\" astype() method is used to explicitly convert data types from one to another\"\"\"\n",
    "\n",
    "# Converting ‘MetColor’ , ‘Automatic’ to object data type\n",
    "\n",
    "cars_data['MetColor']  = cars_data['MetColor'].astype('object')\n",
    "cars_data['Automatic'] = cars_data['Automatic'].astype('object')\n",
    "\n",
    "# =============================================================================\n",
    "# category vs object data type\n",
    "# =============================================================================\n",
    "\"\"\" nbytes() is used to get the total bytes consumed by the elements of the columns\"\"\"\n",
    "\n",
    "# If ‘FuelType’ is of object data type,\n",
    "cars_data['FuelType'].nbytes                     # 11488                 \n",
    "\n",
    "# If ‘FuelType’ is of category data type,\n",
    "cars_data['FuelType'].astype('category').nbytes # 1460\n",
    "\n",
    "# Re-checking the data type of variables after all the conversions\n",
    "cars_data.info()\n",
    "\n",
    "# =============================================================================\n",
    "# Cleaning column ‘Doors’\n",
    "# =============================================================================\n",
    "# Checking unique values of variable ‘Doors’ :\n",
    "print(np.unique(cars_data['Doors']))\n",
    "\n",
    "\"\"\"\n",
    "    replace() is used to replace a value with the desired value \n",
    "    Syntax: DataFrame.replace([to_replace, value, …])\n",
    "\"\"\"\n",
    "\n",
    "cars_data['Doors'].replace('three',3,inplace=True)\n",
    "cars_data['Doors'].replace('four',4,inplace=True)\n",
    "cars_data['Doors'].replace('five',5,inplace=True)\n",
    "\n",
    "# To check the frequencies of unique cateogories in a variable\n",
    "cars_data['Doors'].value_counts()\n",
    "\n",
    "\"\"\"\n",
    "   (or) Pandas- where() \n",
    "\"\"\"\n",
    "cars_data['Doors'].where(cars_data['Doors']!='three',3,inplace=True)\n",
    "\n",
    "\"\"\" \n",
    "   (or) Numpy- where()\n",
    "\"\"\"\n",
    "cars_data['Doors'] = np.where(cars_data['Doors']=='five',5,cars_data['Doors'])\n",
    "\n",
    "# Converting ‘Doors’ to int64:\n",
    "cars_data['Doors'] = cars_data['Doors'].astype('int64')\n",
    "cars_data['Doors'].value_counts()\n",
    "\n",
    "# =============================================================================\n",
    "# To detect missing values\n",
    "# =============================================================================\n",
    "# To check the count of missing values present in each column Dataframe.isnull.sum() is used\n",
    "\n",
    "cars_data.isnull().sum()\n",
    "\n",
    "# =============================================================================\n",
    "#   Cross tables & Correlation\n",
    "# =============================================================================\n",
    "cars_data2 = cars_data.copy()\n",
    "\"\"\"\n",
    "    pandas.crosstab()\n",
    "    - To compute a simple cross-tabulation of one, two (or more) factors\n",
    "    - By default computes a frequency table of the factors \n",
    "\"\"\"\n",
    "# =============================================================================\n",
    "#     # One way table    \n",
    "# =============================================================================\n",
    "\n",
    "pd.crosstab(index=cars_data2['FuelType'], columns='count', dropna=True)\n",
    "# Most of the cars have petrol as fuel type\n",
    "\n",
    "# =============================================================================\n",
    "#     # Two-way table \n",
    "# =============================================================================\n",
    "# To look at the frequency distribution of gearbox types with respect to different\n",
    "# fuel types of the cars\n",
    "\n",
    "pd.crosstab(index   = cars_data2['Automatic'], \n",
    "            columns = cars_data2['FuelType'],\n",
    "            dropna  = True)\n",
    "\n",
    "# =============================================================================\n",
    "#     # Two-way table with proportion / Joint probability\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "Joint probability is the likelihood of two independent events happening at the same time\n",
    "\"\"\"\n",
    "pd.crosstab(index     = cars_data2['Automatic'], \n",
    "            columns   = cars_data2['FuelType'],\n",
    "            normalize = True,\n",
    "            dropna    = True)\n",
    "\n",
    "# 0.82 => Joint probability of manual gear box and petrol fuel type\n",
    "\n",
    "# =============================================================================\n",
    "#     Two-way table - Marginal probability\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "Marginal probability is the probability of the occurrence of the single event\n",
    "\"\"\"\n",
    "pd.crosstab(index     = cars_data2['Automatic'], \n",
    "            columns   = cars_data2['FuelType'],\n",
    "            margins   = True,\n",
    "            dropna    = True,\n",
    "            normalize = True)\n",
    "\n",
    "# Probability of cars having manual gear box when the fuel type are\n",
    "# CNG or Diesel or Petrol is 0.95\n",
    "\n",
    "# =============================================================================\n",
    "#     Two-way table - Conditional probability=> Row sum = 1\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "Conditional probability is the probability of an event ( A ), given that \n",
    "another event ( B ) has already occurred\n",
    "\"\"\"\n",
    "pd.crosstab(index     = cars_data2['Automatic'], \n",
    "            columns   = cars_data2['FuelType'],\n",
    "            margins   = True,\n",
    "            dropna    = True,\n",
    "            normalize = 'index')\n",
    "\n",
    "# Given the gear box, probability of different fuel type\n",
    "\n",
    "# =============================================================================\n",
    "#     Two-way table - Conditional probability => Column sum =1\n",
    "# =============================================================================\n",
    "pd.crosstab(index     = cars_data2['Automatic'], \n",
    "            columns   = cars_data2['FuelType'],\n",
    "            margins   = True,\n",
    "            dropna    = True,\n",
    "            normalize = 'columns')\n",
    "\n",
    "# Given the fuel type, probability of different gear box \n",
    "   \n",
    "# =============================================================================\n",
    "# Correlation    \n",
    "# =============================================================================\n",
    "# Correlation: the strength of association between two variables \n",
    "\n",
    "# Excluding the categorical variables to find the correlation\n",
    "\n",
    "numerical_data = cars_data2.select_dtypes(exclude=[object])\n",
    "print(numerical_data.shape)\n",
    "\n",
    "# Finding the correlation between numerical variables\n",
    "corr_matrix = numerical_data.corr()\n",
    "print(corr_matrix)\n",
    "\n",
    "# Rounding off to two decimal places\n",
    "print(round(corr_matrix,2))\n",
    "\n",
    "# =============================================================================\n",
    "# Identifying missing values\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    " - In Pandas dataframes, missing data is represented by NaN\n",
    "  (an acronym for Not a Number)\n",
    " - To check null values in Pandas dataframes, isnull() and isna() are used\n",
    " - These functions returns a dataframe of Boolean values which are True for NaN values\n",
    "\"\"\"\n",
    "cars_data2 = cars_data.copy()\n",
    "cars_data3 = cars_data2.copy()\n",
    "\n",
    "# To check the count of missing values present in each column \n",
    "\n",
    "print('Data columns with null values:\\n')\n",
    "\n",
    "cars_data2.isna().sum()    #or\n",
    "cars_data2.isnull().sum()\n",
    "\n",
    "# Subsetting the rows that have one or more missing values\n",
    "missing = cars_data2[cars_data2.isnull().any(axis=1)]\n",
    "\n",
    "# =============================================================================\n",
    "# Imputing missing values\n",
    "# =============================================================================\n",
    "\"\"\" Two ways of approach\n",
    "\t - Fill the missing values by mean / median, in case of numerical variable\n",
    "\t - Fill the missing values with the class which has maximum count, in case of\n",
    "       categorical variable\n",
    "\"\"\"\n",
    "\n",
    "# Look at the description to know whether numerical variables should be \n",
    "# imputed with mean or median\n",
    "\"\"\"\n",
    "    DataFrame.describe() - generates descriptive statistics that summarize the \n",
    "    central tendency, dispersion and shape of a dataset’s distribution, excluding NaN values\n",
    "\"\"\"\n",
    "cars_data2.describe()\n",
    "cars_data2.describe(include=\"O\")\n",
    "cars_data2.describe(include=\"all\")\n",
    "\n",
    "\n",
    "# Mean and median of kilometer is far away\n",
    "# Therefore impute with median\n",
    "\n",
    "# ==================== Replacing 'Age' with mean ==============================\n",
    "cars_data2['Age'].mean()\n",
    " \n",
    "cars_data2['Age'].fillna(cars_data2['Age'].mean(), inplace = True)\n",
    "\n",
    "cars_data2['Age'].isnull().sum()\n",
    "\n",
    "# ==================== Replacing 'KM' with median ==============================\n",
    "cars_data2['KM'].median()\n",
    "\n",
    "cars_data2['KM'].fillna(cars_data2['KM'].median(), inplace = True)\n",
    "\n",
    "cars_data2['KM'].isnull().sum()\n",
    "\n",
    "# ==================== Replacing 'HP' with mean ==============================\n",
    "cars_data2['HP'].mean()\n",
    "\n",
    "cars_data2['HP'].fillna(cars_data2['HP'].mean(), inplace = True)\n",
    "\n",
    "cars_data2['HP'].isnull().sum()\n",
    "\n",
    "# Check for missing data after filling values\n",
    "cars_data2.isnull().sum()\n",
    "\n",
    "# ==================== Replacing 'Fuel Type' with mode ========================\n",
    "\"\"\"\n",
    "- Returns a Series containing counts of unique values\n",
    "- The values will be in descending order so that the first element is \n",
    "  the most frequently-occurring element\n",
    "- Excludes NA values by default\n",
    "\"\"\"\n",
    "cars_data2['FuelType'].value_counts() \n",
    "\n",
    "# To get the mode value of FuelType\n",
    "cars_data2['FuelType'].value_counts().index[0]\n",
    "\n",
    "# To fill NA/NaN values using the specified value\n",
    "cars_data2['FuelType'].fillna(cars_data2['FuelType']\\\n",
    "      .value_counts().index[0],\\\n",
    "      inplace = True)\n",
    "\n",
    "cars_data2['FuelType'].isnull().sum()\n",
    "\n",
    "# ==================== Replacing 'MetColor' with mode ========================\n",
    "\n",
    "# To get the mode value of Metcolor\n",
    "cars_data2['MetColor'].mode()\n",
    "\n",
    "# To get categroy with maximum freq\n",
    "# Index 0 will get the category\n",
    "cars_data2['MetColor'].mode()[0]\n",
    "\n",
    "# replacing MetColor with mode\n",
    "cars_data2['MetColor'].fillna(cars_data2['MetColor']\\\n",
    "      .mode()[0], inplace = True)\n",
    "\n",
    "## Check for missing data after filling values \n",
    "cars_data2['MetColor'].isnull().sum()\n",
    "\n",
    "# Check for missing data after filling values\n",
    "cars_data2.isnull().sum()\n",
    "\n",
    "# ==================== Imputation using lambda functionss ========================\n",
    "\n",
    "# To fill the NA/ NaN values in both numerical and categorial variables at one stretch\n",
    "\n",
    "cars_data3 = cars_data3.apply(lambda x:x.fillna(x.value_counts().index[0]))\n",
    "cars_data3.isnull().sum()\n",
    "\n",
    "# Fill all numerical variables at a stretch\n",
    "cars_data3 = cars_data3.apply(lambda x:x.fillna(x.mean()))\n",
    "print('Data columns with null values:\\n', cars_data3.isnull().sum())\n",
    "\n",
    "# Fill numerical and categorial variables at one stretch\n",
    "\n",
    "cars_data3 = cars_data3.apply(lambda x:x.fillna(x.mean()) \\\n",
    "                          if x.dtype=='float' else \\\n",
    "                          x.fillna(x.value_counts().index[0]))\n",
    "\n",
    "print('Data columns with null values:\\n', cars_data3.isnull().sum())\n",
    "\n",
    "# =============================================================================\n",
    "# END OF SCRIPT\n",
    "# =============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfde3252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Jun 12 14:20:21 2019\n",
    "\n",
    "@author: GITAA\n",
    "\"\"\"\n",
    "\n",
    "#=============================================================================\n",
    "# READING DATA\n",
    "#=============================================================================\n",
    "\n",
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "'''\n",
    "=============================================================================\n",
    " Reading .csv format data\n",
    "=============================================================================\n",
    "'''\n",
    "data_csv = pd.read_csv('Iris_data_sample.csv')\n",
    "\n",
    "# =============================================================================\n",
    "# Setting the 1st coulmn 'Unnamed: 0' as index column while reading data\n",
    "# =============================================================================\n",
    "data_csv = pd.read_csv('Iris_data_sample.csv',index_col=0)\n",
    "\n",
    "# =============================================================================\n",
    "# Replacing ‘??’ and ‘# # #’ as 'nan' values\n",
    "# =============================================================================\n",
    "\n",
    "data_csv = pd.read_csv('Iris_data_sample.csv', \n",
    "                       index_col=0,na_values=[\"??\"])\n",
    "\n",
    "data_csv = pd.read_csv('Iris_data_sample.csv',\n",
    "                       index_col=0,na_values=[\"??\",\"###\"])\n",
    "\n",
    "'''\n",
    "=============================================================================\n",
    "Reading .xlsx format data\n",
    "=============================================================================\n",
    "'''\n",
    "data_xlsx = pd.read_excel('Iris_data_sample.xlsx',\n",
    "                        sheet_name='Iris_data')\n",
    "\n",
    "data_xlsx = pd.read_excel('Iris_data_sample.xlsx',index_col=0)\n",
    "\n",
    "data_xlsx = pd.read_excel('Iris_data_sample.xlsx',\n",
    "                        index_col=0,\n",
    "                        na_values=[\"??\",\"###\"])\n",
    "'''\n",
    "=============================================================================\n",
    "Reading .txt format data\n",
    "=============================================================================\n",
    "\n",
    " - Delimitor can be a space or a tab               \n",
    " - Try out to see what works  \n",
    "'''\n",
    " \n",
    "data_txt1 = pd.read_table('Iris_data_sample.txt',delimiter=\"\\t\")\n",
    "data_txt1 = pd.read_table('Iris_data_sample.txt',delimiter=\",\")\n",
    "data_txt1 = pd.read_table('Iris_data_sample.txt',delimiter=\" \") # correct\n",
    "\n",
    "#Instead of using read_table(), read_csv() can also be used to read .txt files\n",
    "data_txt2 = pd.read_csv('Iris_data_sample.txt',delimiter=\" \")\n",
    "\n",
    "# =============================================================================\n",
    "#   END OF SCRIPT\n",
    "# =============================================================================\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
